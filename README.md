# TPM AI Inference Notes | TPM æ¨è«–æ¶æ§‹ç­†è¨˜é›†

Welcome! This repository documents my self-directed learning journey into AI inference systems, deployment pipelines, and related TPM practices.

---

## ğŸ” Overview | ç°¡ä»‹

As a Technical Program Manager (TPM) with a background in system-level development, I created this repository to consolidate and review key concepts in AI infrastructure â€” from inference systems like Triton to deployment workflows using ONNX and Transformer-based architectures.

æœ¬ç­†è¨˜åº«è¨˜éŒ„æˆ‘å° AI æ¨è«–ç³»çµ±ã€æ¨¡å‹éƒ¨ç½²æµç¨‹åŠç›¸é—œ TPM ç®¡ç†å¯¦å‹™çš„å­¸ç¿’èˆ‡æ•´ç†ï¼ŒåŒ…å« Triton æ¶æ§‹ã€ONNX Runtimeã€Transformer åŸºç¤ï¼Œä»¥åŠè·¨éƒ¨é–€å”ä½œæµç¨‹çš„ç†è§£ã€‚

---

## ğŸ“‚ Directory | ç­†è¨˜çµæ§‹

- `Triton-Inference/`ï¼šTriton Inference Server æ¶æ§‹åœ–èˆ‡æ¨è«–æµç¨‹ç­†è¨˜  
- `Transformer-Notes/`ï¼šAttentionã€èªè¨€æ¨¡å‹æ ¸å¿ƒæ¦‚å¿µè§£é‡‹  
- `Neural-Network-Basics/`ï¼šCNN / MLP / æ¿€å‹µå‡½æ•¸å­¸ç¿’è¨˜éŒ„  
- `TPM-Workflows/`ï¼šTPM åœ¨ AI å°ˆæ¡ˆä¸­çš„è§’è‰²ã€è·¨ BU æºé€šæµç¨‹

---

## âœ¨ Highlights | æŠ€è¡“äº®é»

- Triton Inference Server å¤šæ¨¡å‹éƒ¨ç½²æ¶æ§‹ç†è§£
- æ¨è«–æµç¨‹åœ–èˆ‡æ¡†æ¶æ¯”è¼ƒï¼šONNX / TensorRT / PyTorch
- TPM æŠ€èƒ½èˆ‡ AI åŸºç¤çŸ¥è­˜æ•´åˆç­†è¨˜
- ä¸­è‹±å°ç…§ï¼Œå¼·åŒ–ç†è§£èˆ‡è¡¨é”

---

## ğŸ”— References & Connect

- LinkedIn: [your-link]
- Notion TPM Summary Page: [your-link]

